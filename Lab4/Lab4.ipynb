{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Варіант 11. Файл news.csv. В якості текстової моделі використати модель «Сумка слів». Виконати класифікацію за допомогою алгоритмів наївний байєсів класифікатор та випадкові ліси, порівняти їх точність. Спробувати покращити модель випадкові ліси за допомогою GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here are Thursday's biggest analyst calls: App...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buy Las Vegas Sands as travel to Singapore bui...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Piper Sandler downgrades DocuSign to sell, cit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analysts react to Tesla's latest earnings, bre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netflix and its peers are set for a ‘return to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16985</th>\n",
       "      <td>KfW credit line for Uniper could be raised to ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16986</th>\n",
       "      <td>KfW credit line for Uniper could be raised to ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16987</th>\n",
       "      <td>Russian  https://t.co/R0iPhyo5p7 sells 1 bln r...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16988</th>\n",
       "      <td>Global ESG bond issuance posts H1 dip as supra...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16989</th>\n",
       "      <td>Brazil's Petrobras says it signed a $1.25 bill...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16990 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      Here are Thursday's biggest analyst calls: App...      0\n",
       "1      Buy Las Vegas Sands as travel to Singapore bui...      0\n",
       "2      Piper Sandler downgrades DocuSign to sell, cit...      0\n",
       "3      Analysts react to Tesla's latest earnings, bre...      0\n",
       "4      Netflix and its peers are set for a ‘return to...      0\n",
       "...                                                  ...    ...\n",
       "16985  KfW credit line for Uniper could be raised to ...      3\n",
       "16986  KfW credit line for Uniper could be raised to ...      3\n",
       "16987  Russian  https://t.co/R0iPhyo5p7 sells 1 bln r...      3\n",
       "16988  Global ESG bond issuance posts H1 dip as supra...      3\n",
       "16989  Brazil's Petrobras says it signed a $1.25 bill...      3\n",
       "\n",
       "[16990 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('news.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = data['label'].value_counts()\n",
    "min_samples = min(class_counts)\n",
    "data_subset = data.groupby('label').apply(lambda x: x.sample(min_samples)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_text = [preprocess_text(document) for document in data_subset['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(preprocessed_text)\n",
    "y = data_subset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB(alpha=1)\n",
    "nb_cv_scores = cross_val_score(nb_classifier, X_train, y_train, cv=5)\n",
    "nb_cv_mean_score = np.mean(nb_cv_scores)\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "nb_predictions = nb_classifier.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Results: \n",
      "     Actual  Predicted\n",
      "150       3          3\n",
      "406       9          8\n",
      "513      11         11\n",
      "101       2          2\n",
      "535      12         12\n",
      "..      ...        ...\n",
      "319       7          7\n",
      "362       8          8\n",
      "367       8          8\n",
      "264       6         14\n",
      "320       7          7\n",
      "\n",
      "[176 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "nb_results = pd.DataFrame({'Actual': y_test, 'Predicted': nb_predictions})\n",
    "print(\"Naive Bayes Results: \")\n",
    "print(nb_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy:  0.6647727272727273\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes Accuracy: \", nb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy (without GridSearchCV):  0.5795454545454546\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Accuracy (without GridSearchCV): \", rf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100,200,300,400],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2,5,10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_rf_predictions = grid_search.predict(X_test)\n",
    "grid_rf_accuracy = accuracy_score(y_test, grid_rf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy (with GridSearchCV):  0.6193181818181818\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Accuracy (with GridSearchCV): \", grid_rf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results (with GridSearchCV): \n",
      "     Actual  Predicted\n",
      "150       3          3\n",
      "406       9         18\n",
      "513      11         11\n",
      "101       2         12\n",
      "535      12         18\n",
      "..      ...        ...\n",
      "319       7          7\n",
      "362       8          8\n",
      "367       8          8\n",
      "264       6          6\n",
      "320       7          7\n",
      "\n",
      "[176 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "grid_rf_results = pd.DataFrame({'Actual': y_test, 'Predicted': grid_rf_predictions})\n",
    "print(\"Random Forest Results (with GridSearchCV): \")\n",
    "print(grid_rf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.6435258358662613\n"
     ]
    }
   ],
   "source": [
    "best_score = grid_search.best_score_\n",
    "print(\"Best Score: \", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
